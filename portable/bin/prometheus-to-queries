#!/usr/bin/env -S python-venv --virtualenv dotfiles
import logging
import re
import sys
from dataclasses import dataclass
from typing import TextIO

from jmullan_cmd import cmd
from jmullan_logging import easy_logging

logger = logging.getLogger(__name__)

HELP = "# HELP"
TYPE = "# TYPE"
FILTER_REGEX_Q = '^([^=]+)(=|!=|=~|!~)"([^"]+)",?(.*)'
FILTER_REGEX = "^([^=]+)(=|!=|=~|!~)([^,]+),?(.*)"
LABEL_REGEX = r'^([^=]+)="([^"]+)",?(.*)'

value_escapes = {
    "\n": "\\n",
    "\t": "\\t",
    "\\": "\\\\",
}


@dataclass
class Filter:
    key: str
    operator: str
    value: str


def parse_raw_filter(line: str) -> dict[str, Filter]:
    if empty(line):
        return {}
    line = line.strip()
    if line.startswith("{") and line.endswith("}"):
        line = line.removeprefix("{")
        line = line.removesuffix("}")
        return parse_raw_filter(line)
    pairs = {}
    while len(line) > 3:
        line = line.strip()
        # x=y is the minimum filter length!
        match = re.match(FILTER_REGEX_Q, line)
        if not match:
            match = re.match(FILTER_REGEX, line)
        if not match:
            break

        key = match.groups()[0]
        operator = match.groups()[1]
        value = match.groups()[2]
        pairs[key] = Filter(key, operator, value)
        line = match.groups()[3]
    return pairs


def parse_raw_filters(raw_filters: list[str | None] | None) -> dict[str, Filter]:
    if not raw_filters:
        return {}
    filters = {}
    for raw_filter in raw_filters:
        filters.update(parse_raw_filter(raw_filter))
    return filters


def make_filter_string(filters: dict[str, Filter] | None) -> str:
    # {project=~"$project", env=~"$env"}
    if not filters:
        return ""
    parts = []
    for f in filters.values():
        parts.append(f'{f.key}{f.operator}"{f.value}"')
    if parts:
        return "{" + ", ".join(parts) + "}"
    else:
        return ""


def empty(x: str | None) -> bool:
    return x is None or len(x.strip()) == 0


def strip(x: str | None) -> str | None:
    return x.strip() if x is not None else None


def twain(x: str | None) -> tuple[str | None, str | None]:
    if empty(x):
        return None, None
    x = x.strip()
    parts = x.split(" ", 1)
    if not parts or len(parts) == 1:
        return None, None
    stat_name = parts[0].strip()
    stat_help = parts[1].strip()
    if empty(stat_name) or empty(stat_help):
        return None, None
    return parts[0], parts[1]


def get_help(line: str) -> tuple[str | None, str | None]:
    return twain(line)


def get_stat_type(line: str) -> tuple[str | None, str | None]:
    return twain(line)


def parse_labels(line: str) -> set[str] | None:
    if empty(line):
        return None
    line = line.strip()
    if not line.startswith("{") or not line.endswith("}"):
        return None
    line = line.removeprefix("{")
    line = line.removesuffix("}")
    if empty(line):
        return None
    pairs = {}
    while match := re.match(LABEL_REGEX, line):
        key = match.groups()[0]
        value = match.groups()[1]
        pairs[key] = value
        line = match.groups()[2]
    return set(pairs.keys())


def get_stat(line: str) -> tuple[str | None, dict[str, str] | None]:
    stat, _ = twain(line)
    if stat is None:
        return None, None
    curly_location = stat.find("{")
    if curly_location == -1:
        return None, None
    elif curly_location == 0:
        return stat, None
    else:
        stat_name = stat[:curly_location]
        labels = stat[curly_location:]
        return stat_name, parse_labels(labels)


def update_dict_if_not_set(from_dict: dict[str, str], into_dict: dict[str, str]):
    for key, value in from_dict.items():
        if key not in into_dict:
            into_dict[key] = value


def guess_stat_type(stat_name, stat_types):
    stat_type = stat_types.get(stat_name)
    if stat_type is not None:
        return stat_type
    if stat_name.endswith("_count") or stat_name.endswith("_count"):
        return "counter"
    return "gauge"


def expand_suffixes(stat_name: str, suffixes: list[str], value: str) -> dict[str, str]:
    derived_stat_values = {}
    for suffix in suffixes:
        derived_stat_values[f"{stat_name}_{suffix}"] = value
    return derived_stat_values


def get_dimensions(labels: dict) -> str | None:
    if not labels:
        return None
    return " ".join("{{ %s }}" % k for k in labels.keys())


def prometheus_to_queries(
    contents: str, filters: dict[str, Filter] | None = None
) -> str | None:
    if filters is None:
        filters = dict()
    filter_string = make_filter_string(filters)
    stat_names = set()
    stat_helps = {}
    stat_types = {}
    stat_labels: dict[str, dict] = {}
    summaries = set()
    for line in contents.split("\n"):
        line = strip(line)
        if empty(line):
            continue
        if line.startswith(HELP):
            stat_name, stat_help = get_help(line.removeprefix(HELP))
            if empty(stat_name) or empty(stat_help):
                continue
            stat_helps[stat_name] = stat_help
        elif line.startswith(TYPE):
            stat_name, stat_type = get_stat_type(line.removeprefix(TYPE))
            if empty(stat_name) or empty(stat_type):
                continue
            stat_types[stat_name] = stat_type
            if "histogram" == stat_type:
                sub_types = expand_suffixes(
                    stat_name, ["bucket", "count", "sum"], "counter"
                )
                update_dict_if_not_set(sub_types, stat_types)
            elif "summary" == stat_type:
                sub_types = expand_suffixes(stat_name, ["count", "sum"], "counter")
                update_dict_if_not_set(sub_types, stat_types)
                summaries.add(stat_name)
        else:
            stat_name, labels = get_stat(line)
            if empty(stat_name):
                continue
            stat_names.add(stat_name)
            if labels:
                if stat_name not in stat_labels:
                    stat_labels[stat_name] = dict()
                for label in labels:
                    stat_labels[stat_name][label] = None
    for stat_name, stat_type in stat_types.items():
        if "histogram" == stat_type:
            sub_helps = expand_suffixes(
                stat_name, ["bucket", "count", "sum"], stat_helps.get(stat_name)
            )
            update_dict_if_not_set(sub_helps, stat_helps)
        elif "summary" == stat_type:
            sub_helps = expand_suffixes(
                stat_name, ["count", "sum"], stat_helps.get(stat_name)
            )
            update_dict_if_not_set(sub_helps, stat_helps)
    output = []
    # sum(genie_archive_item_priority{project=~"$project", env=~"$env"}) by (project, env, lag_project, item_type, queued_priority) > 0
    stat_defs = {}
    for stat_name in sorted(stat_names):
        stat_type = guess_stat_type(stat_name, stat_types)
        labels = dict()
        labels.update(filters or dict())
        labels.update(stat_labels.get(stat_name) or dict())
        name_filtered = f"{stat_name}{filter_string}"

        if "counter" == stat_type:
            name_filtered = f"rate({name_filtered}[$__rate_interval])"
        if labels:
            label_string = ", ".join(labels.keys())
            if "max" in name_filtered:
                stat_def = f"max by ({label_string}) ({name_filtered})"
            else:
                stat_def = f"sum by ({label_string}) ({name_filtered})"
        else:
            stat_def = f"{name_filtered}"
        dimensions = get_dimensions(labels)
        if dimensions:
            as_legend = f" AS {stat_name} {dimensions}"
        else:
            as_legend = stat_name
        output.append(f"{stat_def}{as_legend}")
        stat_defs[stat_name] = stat_def
    for summary in summaries:
        seconds_def = stat_defs.get(f"{summary}_sum")
        count_def = stat_defs.get(f"{summary}_count")
        if seconds_def is not None and count_def is not None:
            output.append(f"{seconds_def} / {count_def}")
    return "\n".join(output)


class NullWriter(TextIO):
    def write(self, s):
        pass

    def flush(self):
        pass


class Main(cmd.PrintingFileProcessor):
    def __init__(self):
        super().__init__()
        self.parser.add_argument(
            "--name",
            dest="name",
            default=None,
            required=False,
            help="what to call a top-level item",
        )
        self.parser.add_argument(
            "--filters",
            metavar="FILTERS",
            type=str,
            nargs="*",
            help="""Any filters to add to every query: '{env="$env",project="foo"}' "bar=baz" a=b,c=d""",
        )

    def setup(self):
        super().setup()
        if self.args.quiet:
            easy_logging.easy_initialize_logging("DEBUG", stream=NullWriter())
        elif self.args.verbose:
            easy_logging.easy_initialize_logging("DEBUG", stream=sys.stderr)
        else:
            easy_logging.easy_initialize_logging("INFO", stream=sys.stderr)

    def process_contents(self, contents: str) -> str:
        raw_filters = self.args.filters
        return prometheus_to_queries(contents, parse_raw_filters(raw_filters))


if __name__ == "__main__":
    Main().main()
